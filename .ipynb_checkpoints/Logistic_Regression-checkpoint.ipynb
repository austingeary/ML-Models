{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139476a",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3ac3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_ag as models\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187dad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def logistic_regression(x, y, iterations=100, learning_rate=0.01, batch_size=None):\n",
    "    m, n = len(x), len(x[0])\n",
    "    beta_0, beta_other = initialize_params(n)\n",
    "    for _ in range(iterations):\n",
    "        if batch_size:\n",
    "            gradient_beta_0, gradient_beta_other = (\n",
    "                compute_gradients_minibatch(x, y, beta_0, beta_other, m, n, batch_size))\n",
    "        else:\n",
    "            gradient_beta_0, gradient_beta_other = (\n",
    "                compute_gradients(x, y, beta_0, beta_other, m, n))\n",
    "        beta_0, beta_other = update_params(\n",
    "        beta_0, beta_other, gradient_beta_0, gradient_beta_other, learning_rate)\n",
    "    return beta_0, beta_other\n",
    "\n",
    "def initialize_params(n):\n",
    "    beta_0 = 0\n",
    "    beta_other = [random.random() for _ in range(n)]\n",
    "    return beta_0, beta_other\n",
    "\n",
    "def compute_gradients(x, y, beta_0, beta_other, m, n):\n",
    "    gradient_beta_0 = 0\n",
    "    gradient_beta_other = [0] * n\n",
    "    for i, point in enumerate(x):\n",
    "        pred = logistic_function(point, beta_0, beta_other)\n",
    "        for j, feature in enumerate(point):\n",
    "            gradient_beta_other[j] += (\n",
    "                (pred - y[i]) * (feature / m))\n",
    "        gradient_beta_0 += (pred - y[i]) / m\n",
    "    return gradient_beta_0, gradient_beta_other\n",
    "\n",
    "def compute_gradients_minibatch(x, y, beta_0, beta_other, m, n, batch_size):\n",
    "    gradient_beta_0 = 0\n",
    "    gradient_beta_other = [0] * n\n",
    "    for _ in range(batch_size):\n",
    "        i = random.randint(0, m - 1)\n",
    "        point = x[i]\n",
    "        pred = logistic_function(point, beta_0, beta_other)\n",
    "        for j, feature in enumerate(point):\n",
    "            gradient_beta_other[j] += (\n",
    "                (pred - y[i]) * (feature / batch_size))\n",
    "        gradient_beta_0 += (pred - y[i]) / batch_size\n",
    "    return gradient_beta_0, gradient_beta_other\n",
    "\n",
    "def logistic_function(point, beta_0, beta_other):\n",
    "    raw_output = beta_0\n",
    "    for i in range(len(point)):\n",
    "        raw_output += point[i]*beta_other[i]\n",
    "    return sigmoid(raw_output)\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(x))\n",
    "\n",
    "def update_params(beta_0, beta_other, gradient_beta_0, gradient_beta_other, learning_rate):\n",
    "    beta_0 -= gradient_beta_0 * learning_rate\n",
    "    for i in range(len(beta_other)):\n",
    "        beta_other[i] -= (gradient_beta_other[i] * learning_rate)\n",
    "    return beta_0, beta_other\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d46c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
